[DNNMark]
run_mode=composed

[Convolution]
name=block1_1_conv
n=16
c=3
h=224
w=224
previous_layer=null
conv_mode=convolution
kernel_size=7
num_output=96
pad=1
stride=2
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block1_1_conv
name=block1_1_relu
activation_mode=relu

[Pooling]
previous_layer=block1_1_relu
name=pool1_2
pool_mode=max
kernel_size=3
pad=0
stride=2

[Convolution] 
previous_layer=pool1_2
name=block2_1_conv
conv_mode=convolution
kernel_size=1
num_output=16
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block2_1_conv
name=block2_1_relu
activation_mode=relu

[Convolution]  
previous_layer=block2_1_relu
name=block2_2_conv
conv_mode=convolution
kernel_size=1
num_output=64
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block2_2_conv
name=block2_2_relu
activation_mode=relu

[Convolution] 
previous_layer=block2_2_relu
name=block2_3_conv
conv_mode=convolution
kernel_size=3
num_output=64
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block2_3_conv
name=block2_3_relu
activation_mode=relu


[Convolution] 
previous_layer=block2_3_relu
name=block2_4_conv
conv_mode=convolution
kernel_size=1
num_output=16
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block2_4_conv
name=block2_4_relu
activation_mode=relu

[Convolution] 
previous_layer=block2_4_relu
name=block2_5_conv
conv_mode=convolution
kernel_size=1
num_output=64
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block2_5_conv
name=block2_5_relu
activation_mode=relu

[Convolution] 
previous_layer=block2_5_relu
name=block2_6_conv
conv_mode=convolution
kernel_size=3
num_output=64
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block2_6_conv
name=block2_6_relu
activation_mode=relu


[Convolution] 
previous_layer=block2_6_relu
name=block2_7_conv
conv_mode=convolution
kernel_size=1
num_output=32
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block2_7_conv
name=block2_7_relu
activation_mode=relu

[Convolution]  
previous_layer=block2_7_relu
name=block2_8_conv
conv_mode=convolution
kernel_size=1
num_output=128
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block2_8_conv
name=block2_8_relu
activation_mode=relu

[Convolution]
previous_layer=block2_8_relu
name=block2_9_conv
conv_mode=convolution
kernel_size=3
num_output=128
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block2_9_conv
name=block2_9_relu
activation_mode=relu

[Pooling]
previous_layer=block2_9_relu
name=pool2_2
pool_mode=max
kernel_size=3
pad=0
stride=2


[Convolution] 
previous_layer=pool2_2
name=block3_1_conv
conv_mode=convolution
kernel_size=1
num_output=32
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block3_1_conv
name=block3_1_relu
activation_mode=relu

[Convolution]  
previous_layer=block3_1_relu
name=block3_2_conv
conv_mode=convolution
kernel_size=1
num_output=128
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block3_2_conv
name=block3_2_relu
activation_mode=relu

[Convolution] 
previous_layer=block3_2_relu
name=block3_3_conv
conv_mode=convolution
kernel_size=3
num_output=128
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block3_3_conv
name=block3_3_relu
activation_mode=relu

[Convolution] 
previous_layer=block3_3_relu
name=block3_4_conv
conv_mode=convolution
kernel_size=1
num_output=48
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block3_4_conv
name=block3_4_relu
activation_mode=relu

[Convolution] 
previous_layer=block3_4_relu
name=block3_5_conv
conv_mode=convolution
kernel_size=1
num_output=192
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block3_5_conv
name=block3_5_relu
activation_mode=relu

[Convolution]
previous_layer=block3_5_relu
name=block3_6_conv
conv_mode=convolution
kernel_size=3
num_output=192
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block3_6_conv
name=block3_6_relu
activation_mode=relu

[Convolution] 
previous_layer=block3_6_relu
name=block3_7_conv
conv_mode=convolution
kernel_size=1
num_output=48
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block3_7_conv
name=block3_7_relu
activation_mode=relu

[Convolution] 
previous_layer=block3_7_relu
name=block3_8_conv
conv_mode=convolution
kernel_size=1
num_output=192
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block3_8_conv
name=block3_8_relu
activation_mode=relu

[Convolution] 
previous_layer=block3_8_relu
name=block3_9_conv
conv_mode=convolution
kernel_size=3
num_output=192
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block3_9_conv
name=block3_9_relu
activation_mode=relu


[Convolution] 
previous_layer=block3_9_relu
name=block3_10_conv
conv_mode=convolution
kernel_size=1
num_output=48
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block3_10_conv
name=block3_10_relu
activation_mode=relu

[Convolution] 
previous_layer=block3_10_relu
name=block3_11_conv
conv_mode=convolution
kernel_size=1
num_output=256
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block3_11_conv
name=block3_11_relu
activation_mode=relu

[Convolution] 
previous_layer=block3_11_relu
name=block3_12_conv
conv_mode=convolution
kernel_size=3
num_output=256
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block3_12_conv
name=block3_12_relu
activation_mode=relu

[Pooling]
previous_layer=block3_12_relu
name=pool3_3
pool_mode=max
kernel_size=3
pad=0
stride=2

[Convolution] 
previous_layer=pool3_3
name=block4_1_conv
conv_mode=convolution
kernel_size=1
num_output=48
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block4_1_conv
name=block4_1_relu
activation_mode=relu

[Convolution] 
previous_layer=block4_1_relu
name=block4_2_conv
conv_mode=convolution
kernel_size=1
num_output=256
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block4_2_conv
name=block4_2_relu
activation_mode=relu

[Convolution]
previous_layer=block4_2_relu
name=block4_3_conv
conv_mode=convolution
kernel_size=3
num_output=256
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block4_3_conv
name=block4_3_relu
activation_mode=relu

[Pooling]
previous_layer=block4_3_relu
name=pool4_4
pool_mode=max
kernel_size=3
pad=0
stride=2

[FullyConnected]
previous_layer=pool4_4
name=fc1
num_output=1000

[Activation]
previous_layer=fc1
name=relu_fc1
activation_mode=relu















