# Loosely modeled on the starter submit file here:
#   http://chtc.cs.wisc.edu/helloworld.shtml

# Type of job we will be running
universe = vanilla

# Resource requirements we need for this job
request_cpus = 1
request_memory = 2GB
request_disk = 1GB

# Specify the policy for moving files between the execute
# and submit environments
should_transfer_files = YES
when_to_transfer_output = ON_EXIT

# Finally, which files to transfer.  We'll be using CUDA
# and backprop for this example.
# NOTE: the gpgpu-sim configuration files are a macro; to be
# defined later.
initialdir = results
transfer_input_files = /home/pdalmia/projects/gpgpu-sim-v2/condor_workdir/cuda_files.tar.gz, ../hotspot, ../gpgpusim.config, ../config_volta_islip.icnt, ../data/temp_512, ../data/power_512

# We do not specify `transfer_output_files`; accordingly *all* files created in the
# top-level job directory will be copied to the `initialdir` specified above when
# the job completes.

# For backprop, the argument is the network size; increasing this (must be divisible
# by 16) will increase the runtime.  The value 8192 should result in a 2 minute runtime.
arguments = 512 2 2 data/temp_512 data/power_512 #output.out
executable = hotsp.sh

# Filenames for output; recall this will be put into $(initialdir), not the
# submit directory.
output = hotsp.out
error = hotsp.err

# Condor's logging for the job will go to this file.
log = hotsp.log

queue 1

