#   http://chtc.cs.wisc.edu/helloworld.shtml

# Type of job we will be running
universe = docker

docker_image = pdalmia/preyesh_dnnmark


# Resource requirements we need for this job
request_cpus = 1
request_memory = 35GB
request_disk = 8GB

# Specify the policy for moving files between the execute
# and submit environments
should_transfer_files = YES
when_to_transfer_output = ON_EXIT
stream_output = True
# Finally, which files to transfer.  We'll be using CUDA
# and backprop for this example.
# NOTE: the gpgpu-sim configuration files are a macro; to be
# defined later.
initialdir = results
transfer_input_files = /nobackup/preyesh/cuda9/cuda_files.tar.gz, ../resnet, ../gpgpusim.config, ../config_volta_islip.icnt, ../config.txt


# We do not specify `transfer_output_files`; accordingly *all* files created in the
# top-level job directory will be copied to the `initialdir` specified above when
# the job completes.

# For backprop, the argument is the network size; increasing this (must be divisible
# by 16) will increase the runtime.  The value 8192 should result in a 2 minute runtime.
arguments = 
executable = resnet.sh

# Filenames for output; recall this will be put into $(initialdir), not the
# submit directory.
output = resnet.out
error = resnet.err

# Condor's logging for the job will go to this file.
log = resnet.log

queue 1

