#   http://chtc.cs.wisc.edu/helloworld.shtml

# Type of job we will be running
universe = vanilla

# Resource requirements we need for this job
request_cpus = 1
request_memory = 30GB
request_disk = 8GB

# Specify the policy for moving files between the execute
# and submit environments
should_transfer_files = YES
when_to_transfer_output = ON_EXIT
stream_output = True
# Finally, which files to transfer.  We'll be using CUDA
# and backprop for this example.
# NOTE: the gpgpu-sim configuration files are a macro; to be
# defined later.
initialdir = results
transfer_input_files = /nobackup/preyesh/default/cuda_files.tar.gz, ../dnnmark_test_alexnet, ../gpgpusim.config, ../config_volta_islip.icnt, ../dnnmark_test_alexnet.dnnmark

# We do not specify `transfer_output_files`; accordingly *all* files created in the
# top-level job directory will be copied to the `initialdir` specified above when
# the job completes.

# For backprop, the argument is the network size; increasing this (must be divisible
# by 16) will increase the runtime.  The value 8192 should result in a 2 minute runtime.
arguments = -config dnnmark_test_alexnet.dnnmark -debuginfo 1
executable = dnnmark_test_alexnet.sh

# Filenames for output; recall this will be put into $(initialdir), not the
# submit directory.
output = dnnmark_test_alexnet.out
error = dnnmark_test_alexnet.err

# Condor's logging for the job will go to this file.
log = dnnmark_test_alexnet.log

queue 1

